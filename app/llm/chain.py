from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama

from app.config import USE_OPENAI, OLLAMA_HOST, REVIEW_STRICT, REVIEW_LANG
from app.llm.prompt import REVIEW_PROMPT_TEMPLATE, STRICT_REVIEW_PROMPT_TEMPLATE


class ReviewChain:
    def __init__(self):
        if USE_OPENAI:
            self.model = "gpt-4o-mini"
            print(f"Using OpenAI model: {self.model}")
            self.llm_client = ChatOpenAI(
                model=self.model,
                temperature=0.8,
                max_tokens=1024,
            )
        else:
            self.model = "llama3"
            print(f"Using Ollama model: {self.model} with base_url={OLLAMA_HOST}")
            self.llm_client = ChatOllama(
                model=self.model, temperature=0.8, base_url=OLLAMA_HOST
            )
        if not REVIEW_STRICT:
            print("Using non-strict review prompt template")
            self.chain = REVIEW_PROMPT_TEMPLATE | self.llm_client
        else:
            print("Using strict review prompt template")
            self.chain = STRICT_REVIEW_PROMPT_TEMPLATE | self.llm_client

    def format_review_comment(self, review_text: str) -> str:
        now = datetime.now().strftime("%Y-%m-%d %H:%M")

        template = f"""
## PRMate Code Review Report

{review_text.strip()}

*This review was automatically generated by the {self.model} model on {now}.*
"""
        return template

    def generate_review(self, code_diff: str) -> str:
        response = self.chain.invoke(
            {"code_report": code_diff, "language": REVIEW_LANG}
        )

        if isinstance(response, str):
            review_text = response
        elif hasattr(response, "content"):
            review_text = response.content
        else:
            raise ValueError(
                "Unexpected LLM response format: expected str or object with 'content'."
            )

        return self.format_review_comment(review_text)
