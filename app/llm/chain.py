from datetime import datetime
from langchain_ollama import ChatOllama

from app.config import OLLAMA_HOST, REVIEW_LANG
from app.llm.prompt import REVIEW_PROMPT_TEMPLATE, STRICT_REVIEW_PROMPT_TEMPLATE


class ReviewChain:
    def __init__(self):
        self.llm_client = ChatOllama(
            model="llama3", temperature=0.8, base_url=OLLAMA_HOST
        )
        self.chain = REVIEW_PROMPT_TEMPLATE | self.llm_client

    def format_review_comment(self, review_text: str) -> str:
        now = datetime.now().strftime("%Y-%m-%d %H:%M")

        template = f"""
# PRMate Code Review Report

---

{review_text.strip()}

---

*This review was automatically generated by the {self.llm_client.model} model on {now}.*
"""
        return template

    def generate_review(self, code_diff: str) -> str:
        response = self.chain.invoke({"code_report": code_diff, "language": REVIEW_LANG})

        if isinstance(response, str):
            review_text = response
        elif hasattr(response, "content"):
            review_text = response.content
        else:
            raise ValueError(
                "Unexpected LLM response format: expected str or object with 'content'."
            )

        return self.format_review_comment(review_text)
